<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Trang :_)</title>

    <link  href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <link href="css/style.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Space+Mono:400,400i,700,700i&amp;subset=vietnamese" rel="stylesheet">

  </head>

  <body>

    <div class="container">
      <!-- Trang -->
      <div class="column trang">
        <div class="col-lg-12 col-md-12 col-sm-12">
          <p>Experiments & happy accidents</p>
        </div>
      </div>

      <!-- Goethe-Hackathon -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>14th Feb 2019</h6>
          <h3>My work got featured!</h3>

          <p>It's Valentines day and I just found out my Instagram project got featured on Computer Arts almost a year ago (Issue 278, May 2018). Best gift ever lol.</p>

          <p>Writer forgot to send update after the interview. Couldn't get a hold of a hard copy myself so here is the digital version:</p>
          <br><br><br>

          <img src="assets/computerarts.png" style="max-width:100%; height:auto">
          </img>
          <p></p>
        </div>
      </div>

      <!-- Goethe-Hackathon -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>27th Jan 2019</h6>
          <h3>"-sie"</h3>

          <p>My application for <a href="https://n3xtcoder.org/goethe-gamified-machine-learning-accent-recognition">Servus Alexa - Machine Learning Hackathon</a> organised by <a href="https://www.goethe.de/">Goethe Institut</a> and <a href="https://n3xtcoder.org/">N3XTCODER</a>.</p>

          <p><b>Brief</b><br>Develop ideas to acquire audio material of German language learners speaking German (ideally 500 hours) in order to create a training dataset for create a large training set for German accent recognition.</p>

          <p><b>My Concept</b><br>Produce audio-based language lessons based on the Pimsleur Method™, which requires you to be an active listener, never passive. The audio lessons ask you how to say something or to respond to a native speaker.</p>

          <img src="assets/goethe-hackathon/pimsleur.png" style="max-width:100%; height:auto">
          </img>

          <p></p><br><br><br>
          
          <p><b>Why Pimsleur Method™?</b><br>The audio series based on Pimsleur Method™ adheres to a fairly rigid structure and timeline, which means you know exactly when and what the learner speak (text transcript).</p>

          <p>In short:
            <br>- Simple setup (people only need to put on a headphone and listen, no textbook to look at)
            <br>- Lesson structure supports mass data pre-processing and clean data labelling
          </p>

          <br><br><br>
  
          <p><b>Concept illustrated below:</b></p>
          <br>

          <video src="assets/goethe-hackathon/vid1.mp4" controls style="max-width:100%; height:auto">
          </video>
          <small>Cut from one of the original Pimsleur German A1 lessons with added transciption</small>


          <p></p><br><br><br>

          <video src="assets/goethe-hackathon/vid2.mp4" controls style="max-width:100%; height:auto">
          </video>
          <small>Quick edit on a cringy video found on Youtube</small>

          <br><br><br>

          <p><p>The brief was announced beforehand and ideas were submited before the hackathon for approval. 7 ideas were selected. On the hack day, as project owner, I worked together with a team of 6 to realise the concept.</p>

          <p>We did not win.</p>
        </div>
      </div>

      <!-- Nicholas -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>26th Sep 2018</h6>
          <h3>Bye Nicholas!</h3>

          <p>AI erases Romanian communist dictator Nicholas Ceausescu out of his last speech in 1989 using <a target="_blank" href="http://deepangel.media.mit.edu/">Deepangel AI</a>.</p>

          <br><br><br>

          <img src="assets/nicholas/nicholas_final.gif"style="max-width:100%; height:auto">
          </img>

          <br><br><br><br><br>

          <video src="assets/nicholas/nicholas_beforeafter.mp4" controls style="max-width:100%; height:auto">
          </video>
          <small>Before & After</small>

          <p></p><br><br><br>

          <img src="assets/nicholas/progress.gif"style="max-width:100%; height:auto">
          </img>
          <small>Deepangel AI performed on each frame</small>

        </div>
      </div>

      <!-- Github Song -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>8th Sep 2018</h6>
          <h3>Git Graph Song</h3>

          <p>Turned my Github contribution graph into sound. As we moved through times, notes would be played to represent the amount of daily contributions, and the larger the amount, the higher and louder the note would be.</p>

          <p>Data mapped over 3 octaves, starting with octave 4. Sound done in <a target="_blank" href="https://sonic-pi.net/">Sonic Pi</a>.</p>

          <br><br><br>

          <video src="assets/gitsong/github-song-1200x400.mp4" controls style="max-width:100%; height:auto">
          </video>
        </div>
      </div>

      <!-- Björk -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>2nd Sep 2018</h6>
          <h3>(Not) everyone can be Björk</h3>

          <p>Inspired by <a target="_blank" href="https://twitter.com/DrBeef_/status/1034545239027900416">Robbie Barrat's AI generated Balenciaga fashion show</a>, I created my own pose2pose demo that translates my webcam image into Björk in one of her music videos. However, the result was not quite as good as I had expected, hence the title.</p>


          <p>To create the dataset, I used <a target="_blank" href="https://github.com/tensorflow/tfjs-models/tree/master/posenet">Posenet</a> to detect Björk's poses in 400 frames extracted from her <a target="_blank" href="https://www.youtube.com/watch?v=wHuXpWSNa-8">'Big Time Sensuality' music viceo</a>. For training, I used <a target="_blank" href="https://github.com/genekogan/pix2pix-tensorflow">Gene Kogan's version of pix2pix Tensorflow.</a></p>

          <br><br><br>

          <img src="assets/bjork/267.jpg"style="width:100%; height:auto">
          </img>
          <small style="display:block;">Input frame on the right. Detected pose on the left </small>

          <p></p><br><br><br>

          <img src="assets/bjork/trainingset-1.jpg"style="max-width:100%; height:auto">
          </img>
          <small>Complete dataset: 400 pairs of detected pose + input frame</small>

          <p></p><br><br><br>

          <img src="assets/bjork/trainingset-2.jpg"style="max-width:100%; height:auto">
          </img>
          
          

          <p></p><br><br><br>

          <video src="assets/bjork/bjork-1.mp4" controls style="max-width:100%; height:auto">
          </video>

          <small>Installation shown in <a target="_blank" href="https://www.facebook.com/events/271468990352220/?notif_t=plan_user_joined&notif_id=1535387621013541">our final show</a> at Liebieg12</small>

          <p></p><br><br><br>

          <img src="assets/bjork/show-1.jpg"style="max-width:100%; height:auto">
          </img>
          <small>On screen from left to right: input - detected pose - output</small>
          
          <p></p><br><br><br>

          <img src="assets/bjork/show-2.jpg"style="max-width:100%; height:auto">
          </img>
          <small>Physical setup</small>
          
          <p></p><br><br><br>

          <img src="assets/bjork/show-3.jpg"style="max-width:100%; height:auto">
          </img>
          
        </div>
      </div>

      <!-- Makeup Review Generator -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>27th Aug 2018</h6>
          <h3>Fake Review Generator</h3>

          <p>Using char-rnn to generate fake beauty product reviews on <a target="_blank" href="https://yesstyle.com">Yestyle</a> (Asia's equivalent of Sephora/Douglas). Lazy customers can now benefit from their review rewarding system — the more reviews you submit, the more discount you get.</p>
      
          <br><br><br>

          <img src="assets/explain1.jpg"style="max-width:100%; height:auto">
          </img>
          <small>The more reviews you submit, the more discount you get</small>


          <p></p><br><br><br>
          <p>After submitting, these reviews were manually checked by Yesstyle and they all went through!</p>
          <br><br><br>

          <img src="assets/review-reward.png"style="max-width:100%; height:auto">
          </img>
          <small>Got reward with my machine-generated reviews lol</small>

          <p></p><br><br><br>

          <img src="assets/review-online1.jpg"style="max-width:100%; height:auto">
          </img>
          <small>Two of my reviews on Yestyle website with funny English</small>

          <p></p><br><br><br>
          <button><a target="_blank" href="lstm/index.html">Launch experiment</a></button>

        </div>
      </div>

      <!-- Densecap police officers + weed -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>26th Aug 2018</h6>
          <h3>What Neural Networks See</h3>

          <p>Caption generated for a series of images of police officers posing with cananbis plants using <a target="_blank" href="https://github.com/jcjohnson/densecap">Densecap with pre-trained model</a>, when a computer detects objects in images and describes them in natural language.</p>

          <p>I love how it is so good at picking smiling men and green plants.</p>

          <p>Images curated by <a target="_blank" href="http://maxsiedentopf.com/">Max Siedentopf</a></p>
      
          <br><br><br>

          <img src="assets/densecap/20.jpg"style="max-width:100%; height:auto">
          </img>

          <p></p><br><br><br>

          <img src="assets/densecap/18.jpg"style="max-width:100%; height:auto">
          </img>

          <p></p><br><br><br>

          <img src="assets/densecap/16.jpg"style="max-width:100%; height:auto">
          </img>

          <p></p><br><br><br>

          <img src="assets/densecap/21.jpg"style="max-width:100%; height:auto">
          </img>

          <p></p><br><br><br>

          <img src="assets/densecap/8.jpg"style="max-width:100%; height:auto">
          </img>

          <p></p><br><br><br>

          <img src="assets/densecap/10.jpg"style="max-width:100%; height:auto">
          </img>

        </div>
      </div>

      <!-- People with my name-->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>23rd Aug 2018</h6>
          <h3>People With My Name</h3>

          <p>Google searched my name. Scraped and cropped faces out of the first 500 results. Images clustered via <a target="_blank" href="https://lvdmaaten.github.io/tsne/">t-SNE dimensionality reduction technique</a>. It helps to mention that I have a fairly common Vietnamese name.</p>

          <p>Made possible with <a target="_blank" href="https://github.com/montoyamoraga">Aarón Montoya-moraga</a>'s tool for scrapping Google Images and <a target="_blank" href="https://andreasrefsgaard.dk/">Andreas Refgaard</a>'s face-croppping Processing sketch.</p>
      
          <br><br><br>
          <img src="assets/myname-3.jpg"style="max-width:100%;">
          </img>   

          <p></p><br><br><br>
          <img src="assets/myname-3-smallcrop.jpg"style="max-width:100%;">
          </img>   

        </div>
      </div>

      <!-- Art-DCGAN-->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>22nd Aug 2018</h6>
          <h3>Art-DCGAN</h3>

          <p>Using <a target="_blank" href="https://github.com/robbiebarrat/art-DCGAN">Robbie Barrat's art-DCGAN</a> - modified implementation of DCGAN focused on generative art, I trained my own model on a dataset of 1700 Ukiyo-e paintings scraped from <a target="_blank" href="https://www.wikiart.org/en/paintings-by-style/ukiyo-e?select=featured">Wikiart</a>.</p>
      
          <br><br><br>
          <img src="assets/epoch700.png"style="max-width:100%;">
          </img> 
          <small>Some pretty generated Ukiyo-e paintings after epoch 700th</small>
        </div>
      </div>

      <!-- Rachel -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>21st Aug 2018</h6>
          <h3>Cracked Mirror</h3>

          <p>Using rocks to destroy your webcam, the amount of rocks equal to the amount of damage/cracks. Then bring it back to life by throwing in some tapes. </p>

          <br><br><br>
          <video src="assets/videos/crack-trang.mp4" controls style="max-width:100%; height:auto">
          </video>
          
          <p></p><br><br><br>
          <p>How it works:<p>
          <ul>
            <li>
                Use <a target="_blank" href="https://ml4a.github.io/guides/DoodleClassifier/">DoodleClassifier</a>, an openFramworks application, to train a classifer to regconise rocks and tapes via webcam input</li>
            <li>
              After training, the application sends an OSC message for each predicted class as a string to Processing ("rock" and "tape").
            </li>
            <li>
              Based on the amount of received OSC messages, Processing will then calculate how many rocks and tapes are there on the tables in order to output your screen's damage status
            </li>
          </ul>
          <br><br><br><br>
          <img src="assets/setup.jpg"style="max-width:100%;">
          </img>
          <small>Physical setup: Camera looking over a white table</small>

          <p></p><br><br><br>
          <img src="assets/crack-train.gif"style="max-width:100%;">
          </img>
          <small>Train classifier to recognise rocks and tapes on the table</small>
          
          <p></p><br><br><br>
          <p>How damage level is calculated:</p>
          <ul>
            <li>1 tape = +10 health (no crack)</li> 
            <li>1 rock = -10 health (tiny crack)</li> 
            <li>6 rocks + 2 tape = -40 health (severe crack)</li>
          </ul>

          <p></p><br><br><br><br>
          <img src="assets/crack-run.gif"style="max-width:100%;">
          </img>
          <small>Aaand make it crack!</small>

        </div>
      </div>

      <!-- Rachel -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>20th Aug 2018</h6>
          <h3>Virtual Rachel</h3>

          <p>Experience how it's like to be Rachel Uwa (one of my favourite humans!). Made with <a target="_blank" href="https://github.com/genekogan/pix2pix-tensorflow">Tensorflow implementation of pix2pix</a>. Running real-time on a webcam. Input on the left, output on the right.</p>
          
          <p>Inspired by <a target="_blank" href="https://twitter.com/genekogan/status/857922705412239362?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E857922705412239362%7Ctwcon%5Elogo&ref_url=https%3A%2F%2Ftowardsdatascience.com%2Fmedia%2F876344fdc2c234556cacecf9e2b681a5%3FpostId%3Db6771d65bf66">Gene Kogan's Trump puppet</a>, in which he used face tracker to create a generative model that mimic Trump.</p> 
  
          <br><br><br>
          <video src="assets/videos/rachel.mp4" controls style="max-width:100%; height:auto">
          </video>

          <p></p><br><br><br><br>
          <img src="assets/rachel-train.png"style="max-width:100%; height:auto">
          </img>
          <small>Training dataset contains 400 variations of this.</small>

        </div>
      </div>

      <!-- Audio t-SNE -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>20th Aug 2018</h6>
          <h3>Everyday Sound</h3>

          <p>Placing similar-sounding audio recordings near each other using <a target="_blank" href="https://lvdmaaten.github.io/tsne/">t-SNE dimensionality reduction technique</a>. Sound on!</p>

          <p>Dataset: <a target="_blank" href="https://github.com/karoldvl/ESC-50">ESC-50</a>, a collection of 2000 environmetal audio recordings.</p>
  
          <br><br><br>
          <video src="assets/videos/audiotsne.mp4" controls style="max-width:100%; height:auto">
          </video>

        </div>
      </div>

      <!-- Shadertoy -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>19 Aug 2018</h6>
          <h3>Shader Weekend</h3>

          <p>A few Shadertoy shaders I converted to work with Processing 3. More to come.</p>

          <p>Source code will soon be added to Github.</a></p>

          <br><br><br>
          <img src="assets/shaders/cccv.png"style="max-width:100%; height:auto">
          </img>
          <small>CCCV-camera filter</small>

          <br><br><br><br><br>
          <img src="assets/shaders/lsdsheet.png"style="max-width:100%;">
          </img>
          <small>Psychedelic kaleidoscope filter</small>

          <br><br><br><br><br>
          <video controls src="assets/shaders/water.mov"style="max-width:100%; height:auto">
          </video>
          <small>Simple reflective water filter</small>

          <br><br><br><br><br>
          <img src="assets/shaders/water2-1.png"style="max-width:100%; height:auto">
          </img>
          <video controls src="assets/shaders/water2-2.mp4"style="max-width:100%; height:auto">
          </video>
          <small>Reflective water filter with sliders</small>

          <br><br><br><br><br>
          <img src="assets/shaders/clone.jpg"style="max-width:100%; height:auto">
          </img>
          <small>Cloning filter</small>

        </div>
      </div>

      <!-- Southpark Transcript -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>16th Aug 2018</h6>
          <h3>Generated Southpark transcript</h3>

          <p>Custom LSTM trained on 5MB of Southpark transcripts using <a target="_blank" href="https://karpathy.github.io/">Andrej Karpathy's char-rnn code</a>. This was poorly trained (25 epochs) so the result came out somewhat incoherent.</p>

          <br><br><br>
          <img src="assets/charrnn.png"style="max-width:100%; height:auto">
          </img>
          <p></p><br>

          <p>Generated transcript:</p>

          <small>Sain Pandportal Gobbles<br>
            "Haves are gonna wanna been point!"<br>
            Wendy<br>
            "I don't need you talking."<br>
            Cartman<br>
            "I was leave him at the concesses vousing narients? I just leave him! I wourch, and playing on there?”<br>
            Mr. Mady<br>
            "You're been right?!<br> 
            Cartman<br>
            "Wow! I don't frescred another a little kids and everyone kids cannot fine, and talk.”<br>
            Mady<br>
            ”Haw the doy washing state guys are play back, you must pay on the a plane jako, are you got a coupp-think!”<br>
            Russell McCrelsy<br>
            "Apportually need animalid. No-aaant! Thanks,look!”<br>
            Mr. Looosian your horris Driver<br>
            "Hi, not the best simple against a chicken. If soin like, do you guys like that?”<br>
            Kenny<br>
            ”Yeah. No you sure they understand?!  NOW! Starfs! It is!”<br>
            The Boys<br>
            "Bring dollar the swenal and, he's big girlfried away for theballs.”<br>
            Cartman<br>
            "I thought learn here! I was a little big. Hello, Mom, Randy, here. As a place the new circu-sear.”<br>
            Chef<br>
            "I knows, we?"<br>
            Mr. Fred Hankey<br>
            "Does it will dance a complete so we keep them itser tage heals friends, your spy? This is checret. We are a found urized only the period! Thinkling is to your partner, this is a not stop. Yell don't say sound!<br>
            Stan<br>
            "Oh, so you saw it.”<br>
            Cartman<br>
            "Yeah"<br>
            Mr. Adlan<br>
            "Noo."<br>
            Cartman<br>
            "Buy!"<br>
            Polunet<br>
            "That's it?”<br>
            Namie<br>
            “Yeah. Ow, everythin through two perfect.”<br>
            Butters<br>
            "You have the timefor does, fighting, his toning innippy staturing up the balls?”<br>
            Kyle<br>
            "I jurelk, buddy who made Hethorning"<br>
            Brian<br>
            "Oh, rellybegrt is this?”<br>
            Stan<br>
            "Okay I wasterly sleep safe!"<br>
            Jimbo<br>
            "What?? You guys go on?"<br>
            Sharon<br>
            "Were you apologiction, this boys. And I'm not one Goo-Cartman's nogley. The filits. You'll purned Kwiro, operation course!  Yo, no. Nobody are you will be your in-minute and make status now?"<br>
          </small>

        </div>
      </div>

      <!-- Reactive Water Ripples -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>9th Aug 2018</h6>
          <h3>Reactive Water Ripples</h3>

          <p>Audio reactive water ripples. Processing sketch forked from OpenProcessing, modified with the help of <a target="_blank" href="https://github.com/montoyamoraga">Aarón</a>. Would be nice to get this projected on the entire wall of an empty chamber.</p>
  
          <br><br><br>
          <video src="assets/videos/water2.mp4" controls style="max-width:100%; height:auto"></video>

        </div>
      </div>

      <!-- Facial Mole Reader -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>9th Aug 2018</h6>
          <h3>Facial Mole Reader</h3>

          <p>According to Chinese astrology, facial moles can tell your fortune, give insight into your personality. <a target="_blank" href="https://www.yourchineseastrology.com/face-reading/moles/">Read more here.</a></p>

          <p>Browser-based mole reader made using Gene Kogan's ml5js face tracker, trained with Wekinator. As you smile, the meaning of these moles become significantly more positive.</p>

          <br><br><br>
          <img src="assets/facialmole/meredith.png"style="max-width:100%; height:auto">
          </img>
          <small>//UPDATE IMAGE</small>

        </div>
      </div>

      <!-- Slitscan Mirror -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>8th Aug 2018</h6>
          <h3>Slitscan Mirror</h3>

          <p>Processing + "Slitscan" GLSL shader. Trained with supervised machine learning via Wekinator.</p>
          
          <br><br><br>
          <video src="assets/videos/slitscan.mp4" controls style="max-width:100%; height:auto">
          </video>

        </div>
      </div>

      <!-- Neck Stretcher -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>8th Aug 2018</h6>
          <h3>Neck Stretcher</h3>

          <p>Detect (human) neck and stretch it. Made with massive help from <a target="_blank" href="http://andreasrefsgaard.dk/">Andreas Refgaard</a> and <a target="_blank" href="http://merediththomas.co.uk/">Meredith Thomas</a>.</p>

          <p>Red light as prop. :-)</p>
          
          <br><br><br>
          <video src="assets/videos/neck.mp4" controls style="max-width:100%; height:auto">
          </video>

        </div>
      </div>

      <!-- Study with Me -->
      <div class="column">
        <div class="col-lg-8 col-md-10 col-sm-12">
          <h6>7 Aug 2018</h6>
          <h3>Study with Me</h3>

          <p>Application made for my sister based on the concept of <a target="_blank" href="https://www.youtube.com/watch?v=tihncflS0h4">Study with Me</a>. This plays an 1-hour long video of a student quitely studying and will nag her everytime she looks at the computer. Audio voice generated using Google Translate.</p>

          <br><br><br>
          <video src="assets/videos/studywithme.mp4" controls style="max-width:100%; height:auto">
          </video>
          <p></p><br>

          <p>Audio transcripts (Vietnamese):</p>
          <ul>
            <li>Mích, học bài đi <i>Mích, back to study</i></li>
            <li>Mích đừng mất tập trung nữa <i>Mích, stop losing focus</i></li>
            <li>Học đi cho mẹ vui <i>Mích, study and make your mom happy</i></li>
            <li>Mích đang nghĩ gì đấy? <i>Mích, what are you doing?</i></li>
            <li>Học đi nhìn cái gì <i>What are you looking at?</i></li>
            <li>Đã bảo rồi đừng có mất tập trung nữa <i>I told you so, focus</i></li>
            <li>Mệt thì nghỉ, nhưng mà 2 phút thôi <i>Get some rest if you're tired, but just 2 minutes</i></li>
            <li>Okay, hết 2 phút rồi, học đi <i>Okay, 2 minutes is over, back to study</i></li>
          </ul>

        </div>
      </div>

    </div>
    <!-- /.container -->

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  </body>

</html>
